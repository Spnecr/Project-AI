{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Classification with The Help Of Natural Language Processing Technique. \n",
    "Fake news detection is a hot topic in the field of natural language processing.\n",
    "We consume news through several mediums throughout the day in our daily routine, but sometimes it becomes difficult to decide which one is fake and which one is authentic. Our job is to create a model which predicts whether a given news is real or fake."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Project Flow:\n",
    "    1. Problem Statement\n",
    "    2. Data Gathering\n",
    "    3. Data Preprocessing : Here we perform some operation on data\n",
    "        A. Tokenization\n",
    "        B. Lower Case\n",
    "        C. Stopwords \n",
    "        D. Lemmatization / Stemming\n",
    "    4. Vectorization (Convert Text data into the Vector):\n",
    "        A. Bag Of Words (CountVectorizer)\n",
    "        B. TF-IDF\n",
    "    5. Model Building :\n",
    "        A. Model Object Initialization\n",
    "        B. Train and Test Model\n",
    "    6. Model Evaluation :\n",
    "        A. Accuracy Score\n",
    "        B. Confusition Matrix\n",
    "        C. Classification Report\n",
    "    7. Model Deployment\n",
    "    8. Prediction on Client Data        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Tanggal</th>\n",
       "      <th>Judul</th>\n",
       "      <th>Narasi</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17 February 2024</td>\n",
       "      <td>Autisme Bukan Penyakit, Psikolog: Ada 3 Cara M...</td>\n",
       "      <td>Psikolog Vitriani Sumarlis menjelaskan bahwa a...</td>\n",
       "      <td>https://www.kompas.com/edu/read/2024/02/17/125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4 April 2024</td>\n",
       "      <td>Guru Besar UGM Luncurkan Buku Menolak Dehumani...</td>\n",
       "      <td>Guru Besar Departemen Sosiologi UGM Prof. Dr. ...</td>\n",
       "      <td>https://ugm.ac.id/id/berita/guru-besar-ugm-lun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>23 April 2024</td>\n",
       "      <td>Hari Buku Sedunia Diperingati Setiap 23 April,...</td>\n",
       "      <td>Hari buku sedunia atau World Book Day dipering...</td>\n",
       "      <td>https://uici.ac.id/hari-buku-sedunia-diperinga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>15 May 2024</td>\n",
       "      <td>Keindahan Indonesia dalam Buku Fotografi Karya...</td>\n",
       "      <td>Bagi penggemar buku-buku berkualitas, tanggal ...</td>\n",
       "      <td>https://kemenparekraf.go.id/ragam-ekonomi-krea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>30 May 2024</td>\n",
       "      <td>Greysia Polii Luncurkan Buku Biografi</td>\n",
       "      <td>Menjadi peraih medali emas Olimpiade adalah im...</td>\n",
       "      <td>https://pbdjarum.org/berita/diluar-arena/20240...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label           Tanggal                                              Judul  \\\n",
       "0      0  17 February 2024  Autisme Bukan Penyakit, Psikolog: Ada 3 Cara M...   \n",
       "1      0      4 April 2024  Guru Besar UGM Luncurkan Buku Menolak Dehumani...   \n",
       "2      0     23 April 2024  Hari Buku Sedunia Diperingati Setiap 23 April,...   \n",
       "3      0       15 May 2024  Keindahan Indonesia dalam Buku Fotografi Karya...   \n",
       "4      0       30 May 2024              Greysia Polii Luncurkan Buku Biografi   \n",
       "\n",
       "                                              Narasi  \\\n",
       "0  Psikolog Vitriani Sumarlis menjelaskan bahwa a...   \n",
       "1  Guru Besar Departemen Sosiologi UGM Prof. Dr. ...   \n",
       "2  Hari buku sedunia atau World Book Day dipering...   \n",
       "3  Bagi penggemar buku-buku berkualitas, tanggal ...   \n",
       "4  Menjadi peraih medali emas Olimpiade adalah im...   \n",
       "\n",
       "                                              Source  \n",
       "0  https://www.kompas.com/edu/read/2024/02/17/125...  \n",
       "1  https://ugm.ac.id/id/berita/guru-besar-ugm-lun...  \n",
       "2  https://uici.ac.id/hari-buku-sedunia-diperinga...  \n",
       "3  https://kemenparekraf.go.id/ragam-ekonomi-krea...  \n",
       "4  https://pbdjarum.org/berita/diluar-arena/20240...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Label    1000 non-null   int64 \n",
      " 1   Tanggal  1000 non-null   object\n",
      " 2   Judul    1000 non-null   object\n",
      " 3   Narasi   1000 non-null   object\n",
      " 4   Source   1000 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 39.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    642\n",
       "0    358\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label      0\n",
       "Tanggal    0\n",
       "Judul      0\n",
       "Narasi     0\n",
       "Source     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna() #Handled Missing values by droping those rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label      0\n",
       "Tanggal    0\n",
       "Judul      0\n",
       "Narasi     0\n",
       "Source     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Label</th>\n",
       "      <th>Tanggal</th>\n",
       "      <th>Judul</th>\n",
       "      <th>Narasi</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17 February 2024</td>\n",
       "      <td>Autisme Bukan Penyakit, Psikolog: Ada 3 Cara M...</td>\n",
       "      <td>Psikolog Vitriani Sumarlis menjelaskan bahwa a...</td>\n",
       "      <td>https://www.kompas.com/edu/read/2024/02/17/125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4 April 2024</td>\n",
       "      <td>Guru Besar UGM Luncurkan Buku Menolak Dehumani...</td>\n",
       "      <td>Guru Besar Departemen Sosiologi UGM Prof. Dr. ...</td>\n",
       "      <td>https://ugm.ac.id/id/berita/guru-besar-ugm-lun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23 April 2024</td>\n",
       "      <td>Hari Buku Sedunia Diperingati Setiap 23 April,...</td>\n",
       "      <td>Hari buku sedunia atau World Book Day dipering...</td>\n",
       "      <td>https://uici.ac.id/hari-buku-sedunia-diperinga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15 May 2024</td>\n",
       "      <td>Keindahan Indonesia dalam Buku Fotografi Karya...</td>\n",
       "      <td>Bagi penggemar buku-buku berkualitas, tanggal ...</td>\n",
       "      <td>https://kemenparekraf.go.id/ragam-ekonomi-krea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>30 May 2024</td>\n",
       "      <td>Greysia Polii Luncurkan Buku Biografi</td>\n",
       "      <td>Menjadi peraih medali emas Olimpiade adalah im...</td>\n",
       "      <td>https://pbdjarum.org/berita/diluar-arena/20240...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Label           Tanggal  \\\n",
       "0      0      0  17 February 2024   \n",
       "1      1      0      4 April 2024   \n",
       "2      2      0     23 April 2024   \n",
       "3      3      0       15 May 2024   \n",
       "4      4      0       30 May 2024   \n",
       "\n",
       "                                               Judul  \\\n",
       "0  Autisme Bukan Penyakit, Psikolog: Ada 3 Cara M...   \n",
       "1  Guru Besar UGM Luncurkan Buku Menolak Dehumani...   \n",
       "2  Hari Buku Sedunia Diperingati Setiap 23 April,...   \n",
       "3  Keindahan Indonesia dalam Buku Fotografi Karya...   \n",
       "4              Greysia Polii Luncurkan Buku Biografi   \n",
       "\n",
       "                                              Narasi  \\\n",
       "0  Psikolog Vitriani Sumarlis menjelaskan bahwa a...   \n",
       "1  Guru Besar Departemen Sosiologi UGM Prof. Dr. ...   \n",
       "2  Hari buku sedunia atau World Book Day dipering...   \n",
       "3  Bagi penggemar buku-buku berkualitas, tanggal ...   \n",
       "4  Menjadi peraih medali emas Olimpiade adalah im...   \n",
       "\n",
       "                                              Source  \n",
       "0  https://www.kompas.com/edu/read/2024/02/17/125...  \n",
       "1  https://ugm.ac.id/id/berita/guru-besar-ugm-lun...  \n",
       "2  https://uici.ac.id/hari-buku-sedunia-diperinga...  \n",
       "3  https://kemenparekraf.go.id/ragam-ekonomi-krea...  \n",
       "4  https://pbdjarum.org/berita/diluar-arena/20240...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Autisme Bukan Penyakit, Psikolog: Ada 3 Cara Mendampingi'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Judul'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Label</th>\n",
       "      <th>Judul</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Autisme Bukan Penyakit, Psikolog: Ada 3 Cara M...</td>\n",
       "      <td>https://www.kompas.com/edu/read/2024/02/17/125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Guru Besar UGM Luncurkan Buku Menolak Dehumani...</td>\n",
       "      <td>https://ugm.ac.id/id/berita/guru-besar-ugm-lun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Hari Buku Sedunia Diperingati Setiap 23 April,...</td>\n",
       "      <td>https://uici.ac.id/hari-buku-sedunia-diperinga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Keindahan Indonesia dalam Buku Fotografi Karya...</td>\n",
       "      <td>https://kemenparekraf.go.id/ragam-ekonomi-krea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Greysia Polii Luncurkan Buku Biografi</td>\n",
       "      <td>https://pbdjarum.org/berita/diluar-arena/20240...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Label                                              Judul  \\\n",
       "0      0      0  Autisme Bukan Penyakit, Psikolog: Ada 3 Cara M...   \n",
       "1      1      0  Guru Besar UGM Luncurkan Buku Menolak Dehumani...   \n",
       "2      2      0  Hari Buku Sedunia Diperingati Setiap 23 April,...   \n",
       "3      3      0  Keindahan Indonesia dalam Buku Fotografi Karya...   \n",
       "4      4      0              Greysia Polii Luncurkan Buku Biografi   \n",
       "\n",
       "                                              Source  \n",
       "0  https://www.kompas.com/edu/read/2024/02/17/125...  \n",
       "1  https://ugm.ac.id/id/berita/guru-besar-ugm-lun...  \n",
       "2  https://uici.ac.id/hari-buku-sedunia-diperinga...  \n",
       "3  https://kemenparekraf.go.id/ragam-ekonomi-krea...  \n",
       "4  https://pbdjarum.org/berita/diluar-arena/20240...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Tanggal','Narasi'],axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = 'The quick brown fox jumps over the lazy dog'\n",
    "sample_data = sample_data.split()\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Make Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = [data.lower() for data in sample_data]\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ada', 'adalah', 'adanya', 'adapun', 'agak', 'agaknya', 'agar', 'akan', 'akankah', 'akhir']\n",
      "758\n"
     ]
    }
   ],
   "source": [
    "stopwords = stopwords.words('indonesian')\n",
    "print(stopwords[0:10])\n",
    "print(len(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = [data for data in sample_data if data not in stopwords]\n",
    "print(sample_data)\n",
    "len(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'quick', 'brown', 'fox', 'jump', 'over', 'the', 'lazi', 'dog']\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "sample_data_stemming = [ps.stem(data) for data in sample_data]\n",
    "print(sample_data_stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\fikri\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'quick', 'brown', 'fox', 'jump', 'over', 'the', 'lazy', 'dog']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "lm = WordNetLemmatizer()\n",
    "sample_data_lemma = [lm.lemmatize(data) for data in sample_data]\n",
    "print(sample_data_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = WordNetLemmatizer()\n",
    "corpus = []\n",
    "for i in range (len(df)):\n",
    "    review = re.sub('^a-zA-Z0-9', ' ', df['Judul'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [lm.lemmatize(x) for x in review if x not in stopwords]\n",
    "    review = \" \".join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Autisme Bukan Penyakit, Psikolog: Ada 3 Cara Mendampingi'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Judul'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'autisme penyakit, psikolog: 3 mendampingi'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Vectorization (Convert Text data into the Vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer()\n",
    "x = tf.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Label']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting into the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.3, random_state = 10, stratify = y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 700)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train),len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rf.predict(x_test)\n",
    "accuracy_score_ = accuracy_score(y_test,y_pred) \n",
    "accuracy_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation:\n",
    "    \n",
    "    def __init__(self,model,x_train,x_test,y_train,y_test):\n",
    "        self.model = model\n",
    "        self.x_train = x_train\n",
    "        self.x_test = x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def train_evaluation(self):\n",
    "        y_pred_train = self.model.predict(self.x_train)\n",
    "        \n",
    "        acc_scr_train = accuracy_score(self.y_train,y_pred_train)\n",
    "        print(\"Accuracy Score On Training Data Set :\",acc_scr_train)\n",
    "        print()\n",
    "        \n",
    "        con_mat_train = confusion_matrix(self.y_train,y_pred_train)\n",
    "        print(\"Confusion Matrix On Training Data Set :\\n\",con_mat_train)\n",
    "        print()\n",
    "        \n",
    "        class_rep_train = classification_report(self.y_train,y_pred_train)\n",
    "        print(\"Classification Report On Training Data Set :\\n\",class_rep_train)\n",
    "        \n",
    "        \n",
    "    def test_evaluation(self):\n",
    "        y_pred_test = self.model.predict(self.x_test)\n",
    "        \n",
    "        acc_scr_test = accuracy_score(self.y_test,y_pred_test)\n",
    "        print(\"Accuracy Score On Testing Data Set :\",acc_scr_test)\n",
    "        print()\n",
    "        \n",
    "        con_mat_test = confusion_matrix(self.y_test,y_pred_test)\n",
    "        print(\"Confusion Matrix On Testing Data Set :\\n\",con_mat_test)\n",
    "        print()\n",
    "        \n",
    "        class_rep_test = classification_report(self.y_test,y_pred_test)\n",
    "        print(\"Classification Report On Testing Data Set :\\n\",class_rep_test)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score On Training Data Set : 1.0\n",
      "\n",
      "Confusion Matrix On Training Data Set :\n",
      " [[251   0]\n",
      " [  0 449]]\n",
      "\n",
      "Classification Report On Training Data Set :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       251\n",
      "           1       1.00      1.00      1.00       449\n",
      "\n",
      "    accuracy                           1.00       700\n",
      "   macro avg       1.00      1.00      1.00       700\n",
      "weighted avg       1.00      1.00      1.00       700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking the accuracy on training dataset\n",
    "\n",
    "Evaluation(rf,x_train, x_test, y_train, y_test).train_evaluation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score On Testing Data Set : 0.8\n",
      "\n",
      "Confusion Matrix On Testing Data Set :\n",
      " [[ 50  57]\n",
      " [  3 190]]\n",
      "\n",
      "Classification Report On Testing Data Set :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.47      0.62       107\n",
      "           1       0.77      0.98      0.86       193\n",
      "\n",
      "    accuracy                           0.80       300\n",
      "   macro avg       0.86      0.73      0.74       300\n",
      "weighted avg       0.83      0.80      0.78       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking the accuracy on testing dataset\n",
    "Evaluation(rf,x_train, x_test, y_train, y_test).test_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    \n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        \n",
    "    def text_preprocessing_user(self):\n",
    "        lm = WordNetLemmatizer()\n",
    "        pred_data = [self.data]    \n",
    "        preprocess_data = []\n",
    "        for data in pred_data:\n",
    "            review = re.sub('^a-zA-Z0-9',' ', data)\n",
    "            review = review.lower()\n",
    "            review = review.split()\n",
    "            review = [lm.lemmatize(x) for x in review if x not in stopwords]\n",
    "            review = \" \".join(review)\n",
    "            preprocess_data.append(review)\n",
    "        return preprocess_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Autisme Bukan Penyakit, Psikolog: Ada 3 Cara Mendampingi'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Judul'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['depo plumpang terbakar, anggota dpr pertamina pastikan pasokan bbm terganggu']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"Depo Plumpang Terbakar, Anggota DPR Minta Pertamina Pastikan Pasokan BBM Tak Terganggu\"\n",
    "Preprocessing(data).text_preprocessing_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction:\n",
    "    \n",
    "    def __init__(self,pred_data, model):\n",
    "        self.pred_data = pred_data\n",
    "        self.model = model\n",
    "        \n",
    "    def prediction_model(self):\n",
    "        preprocess_data = Preprocessing(self.pred_data).text_preprocessing_user()\n",
    "        data = tf.transform(preprocess_data)\n",
    "        prediction = self.model.predict(data)\n",
    "        \n",
    "        if prediction [0] == 1 :\n",
    "            return \"The News Is Fake\"\n",
    "        \n",
    "        else:\n",
    "            return \"The News Is Real\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The News Is Fake'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"The News Is Fake\"\n",
    "Prediction(data,rf).prediction_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paus Fransiskus ke Indonesia'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Judul'][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The News Is Real'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data = 'Paus Fransiskus ke Indonesia'\n",
    "Prediction(user_data,rf).prediction_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
